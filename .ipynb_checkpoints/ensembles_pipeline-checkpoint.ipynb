{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from ipynb.fs.full.data_wrangling import * #Data preprocessing notebook\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SCORINGS = [\n",
    "    'accuracy'\n",
    "#     'f1',\n",
    "#     'precision',\n",
    "#     'recall',\n",
    "#     'roc_auc'\n",
    "]\n",
    "\n",
    "cv_splits = 5\n",
    "repetitions = 3\n",
    "RANDOM_STATE = 42\n",
    "cross_validation_setting = RepeatedStratifiedKFold(n_splits=cv_splits,\n",
    "                                                   n_repeats=repetitions,\n",
    "                                                   random_state= RANDOM_STATE)\n",
    "\n",
    "def model_evaluation(model, features, target, \n",
    "                     cv = cross_validation_setting):\n",
    "    scores = dict()\n",
    "    formatted_scores = dict()\n",
    "    formatted_scores['model'] = model\n",
    "    for score_metric in SCORINGS:\n",
    "        scores[score_metric] = cross_val_score(model,\n",
    "                                               features,\n",
    "                                               target,\n",
    "                                               scoring = score_metric)\n",
    "        formatted_scores[score_metric + \" score\"] = scores[score_metric].mean()\n",
    "        formatted_scores[score_metric + \" std\"] = scores[score_metric].std()\n",
    "        fig = plt.figure()\n",
    "        fig.suptitle('Algorithm Comparison')\n",
    "        ax = fig.add_subplot(111)\n",
    "        plt.boxplot(scores[score_metric])\n",
    "        plt.show()\n",
    "    \n",
    "    return formatted_scores\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Config for every experiment\n",
    "\"\"\"\n",
    "RANDOM_STATE = 0\n",
    "VOTING_METHOD = 'soft'\n",
    "results = pd.DataFrame(columns = ['model', \"accuracy score\", \"accuracy std\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Getting the best weak learners (GridSearchCV section)\n",
    "\"\"\"\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot perform reduce with flexible type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-41f5dbf6ef86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m                              refit = True)\n\u001b[0;32m      9\u001b[0m \u001b[0mselected_log_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_reg_gridsearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselected_log_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-5e7692e9a9dc>\u001b[0m in \u001b[0;36mmodel_evaluation\u001b[1;34m(model, features, target, cv)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Algorithm Comparison'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m111\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mboxplot\u001b[1;34m(x, notch, sym, vert, whis, positions, widths, patch_artist, bootstrap, usermedians, conf_intervals, meanline, showmeans, showcaps, showbox, showfliers, boxprops, labels, flierprops, medianprops, meanprops, capprops, whiskerprops, manage_ticks, autorange, zorder, data)\u001b[0m\n\u001b[0;32m   2510\u001b[0m         \u001b[0mwhiskerprops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwhiskerprops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmanage_ticks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanage_ticks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2511\u001b[0m         \u001b[0mautorange\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mautorange\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzorder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mzorder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2512\u001b[1;33m         **({\"data\": data} if data is not None else {}))\n\u001b[0m\u001b[0;32m   2513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1436\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1438\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mboxplot\u001b[1;34m(self, x, notch, sym, vert, whis, positions, widths, patch_artist, bootstrap, usermedians, conf_intervals, meanline, showmeans, showcaps, showbox, showfliers, boxprops, labels, flierprops, medianprops, meanprops, capprops, whiskerprops, manage_ticks, autorange, zorder)\u001b[0m\n\u001b[0;32m   3682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3683\u001b[0m         bxpstats = cbook.boxplot_stats(x, whis=whis, bootstrap=bootstrap,\n\u001b[1;32m-> 3684\u001b[1;33m                                        labels=labels, autorange=autorange)\n\u001b[0m\u001b[0;32m   3685\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnotch\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3686\u001b[0m             \u001b[0mnotch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'boxplot.notch'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\u001b[0m in \u001b[0;36mboxplot_stats\u001b[1;34m(X, whis, bootstrap, labels, autorange)\u001b[0m\n\u001b[0;32m   1175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m         \u001b[1;31m# arithmetic mean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m         \u001b[0mstats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;31m# medians and quartiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m   3371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3372\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[1;32m-> 3373\u001b[1;33m                           out=out, **kwargs)\n\u001b[0m\u001b[0;32m   3374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m    158\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         ret = um.true_divide(\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot perform reduce with flexible type"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg_grid={'C':[0.001,0.01,.09,1,5,10],\n",
    "              \"penalty\":[\"l1\",\"l2\"]} #l1 lasso l2 ridge\n",
    "lr = LogisticRegression(random_state=RANDOM_STATE)\n",
    "log_reg_gridsearch = GridSearchCV(lr, param_grid = log_reg_grid,\n",
    "                             refit = True)\n",
    "selected_log_reg = log_reg_gridsearch.fit(X,Y).best_estimator_\n",
    "results = results.append(model_evaluation(selected_log_reg, X, Y), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "K Neighbors\n",
    "\"\"\"\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k_range = list(range(1,31))\n",
    "weight_options = [\"uniform\", \"distance\"]\n",
    "\n",
    "knn_grid = dict(n_neighbors = k_range, \n",
    "                weights = weight_options)\n",
    "knn = KNeighborsClassifier()\n",
    "knn_gridsearch =GridSearchCV(knn, param_grid = knn_grid,\n",
    "                             refit = True)\n",
    "selected_knn = knn_gridsearch.fit(X, Y).best_estimator_\n",
    "results = results.append(model_evaluation(selected_knn, X , Y), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Support Vector Machines\n",
    "\"\"\"\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "            'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "            'kernel': ['rbf']} \n",
    "  \n",
    "svm_gridsearch = GridSearchCV(SVC(),\n",
    "                              param_grid = svm_grid,\n",
    "                              refit = True)\n",
    "\n",
    "selected_svm = svm_gridsearch.fit(X,Y).best_estimator_\n",
    "model_evaluation(selected_svm, X , Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "\n",
    "nb_params = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "nb_gridsearch = GridSearchCV(estimator=nb, \n",
    "                     param_grid = nb_params,\n",
    "                     refit = True)\n",
    "selected_nb = nb_gridsearch.fit(X,Y).best_estimator_\n",
    "model_evaluation(selected_nb, X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Boosting Algorithms\"\"\"\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "boosting_models = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost\n",
    "ab_param_grid = {\n",
    "    'n_estimators' : [100, 300, 500],\n",
    "    'learning_rate' : [1e-3, 1e-2, 1e-1, 1]\n",
    "}\n",
    "ab_model = AdaBoostClassifier(random_state = RANDOM_STATE)\n",
    "xgb_gridsearch = GridSearchCV(ab_model,\n",
    "                              param_grid = ab_param_grid,\n",
    "                              refit = True)\n",
    "\n",
    "selected_xgb = xgb_gridsearch.fit(X, Y).best_estimator_\n",
    "model_evaluation(selected_xgb, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "parameters = {\n",
    "            'max_depth': [3, 4, 5],\n",
    "            'learning_rate': [0.01, 0.1, 1],\n",
    "            'n_estimators': [200, 400],\n",
    "            'gamma': [0.01, 0.1, 0.2],\n",
    "            'min_child_weight': [0, 0.5, 1],\n",
    "            'max_delta_step': [0],\n",
    "            'subsample': [0.7, 1],\n",
    "            'colsample_bytree': [0.6, 1],\n",
    "            'reg_alpha': [0, 1e-2, 1],\n",
    "            'reg_lambda': [0, 1e-2, 1],\n",
    "            }\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(silent = True,\n",
    "                              random_state = RANDOM_STATE)\n",
    "\n",
    "xgb_gridsearch = GridSearchCV(xgb_model,\n",
    "                              parameters,\n",
    "                              refit = True)\n",
    "\n",
    "selected_xgb = xgb_gridsearch.fit(X, Y).best_estimator_\n",
    "model_evaluation(selected_xgb, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Bagging Algorithms\"\"\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bagging_models = dict()\n",
    "bagging_models['rf'] = RandomForestClassifier(random_state = RANDOM_STATE)\n",
    "bagging_models['et'] = ExtraTreesClassifier(random_state = RANDOM_STATE)\n",
    "bagging_models['bdt'] = BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                          random_state = RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#RandomForest\n",
    "rf_grid = {\n",
    "    'max_depth': [4, 5, 6],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [200, 400]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state = RANDOM_STATE)\n",
    "rf_gridsearch = GridSearchCV(rf, param_grid = rf_grid,\n",
    "                             refit = True)\n",
    "selected_rf = rf_gridsearch.fit(X, Y).best_estimator_\n",
    "model_evaluation(selected_rf, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra Trees\n",
    "\n",
    "et_grid = {\n",
    "    'max_depth': [4, 5, 6],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [200, 400],\n",
    "    'oob_score': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Stacking Ensemble\"\"\"\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "stacking_estimators = [\n",
    "    ('lr', selected_lr),\n",
    "    ('knn', selected_knn),\n",
    "    ('svm', selected_svm),\n",
    "    ('gnb', selected_nb),\n",
    "    ('dt', selected_dt)\n",
    "]\n",
    "\n",
    "final_estimator = selected_lr\n",
    "\n",
    "stacking_model = StackingClassifier(estimators = stacking_estimators,\n",
    "                                    final_estimator = final_estimator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Voting Ensemble\"\"\"\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_estimators = [\n",
    "    ('lr', LogisticRegression(random_state=RANDOM_STATE)),\n",
    "    ('knn', KNeighborsClassifier()),\n",
    "    ('svm', SVC(random_state=RANDOM_STATE)),\n",
    "    ('gnb', GaussianNB()),\n",
    "    ('dt', DecisionTreeClassifier(random_state=RANDOM_STATE))\n",
    "]\n",
    "\n",
    "voting_classifier = VotingClassifier(voting_estimators,\n",
    "                                     voting=VOTING_METHOD)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
