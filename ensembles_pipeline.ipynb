{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from ipynb.fs.full.data_wrangling import * #Data preprocessing notebook\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "import statistics\n",
    "\n",
    "\n",
    "SCORINGS = {\n",
    "    'f1': make_scorer(f1_score, average = None),\n",
    "    'precision': make_scorer(precision_score, average = None),\n",
    "    'recall': make_scorer(recall_score, average = None),\n",
    "    'roc_auc': make_scorer(roc_auc_score, average = None)\n",
    "}\n",
    "\n",
    "cv_splits = 10\n",
    "repetitions = 1\n",
    "RANDOM_STATE = 42\n",
    "cross_validation_setting = RepeatedStratifiedKFold(n_splits=cv_splits,\n",
    "                                                   n_repeats=repetitions,\n",
    "                                                   random_state= RANDOM_STATE)\n",
    "        \n",
    "def cross_validate(model, X_train, X_test, y_train, y_test, metric):\n",
    "    for index in range(len(X_train)):\n",
    "        model.fit(X_train, y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "def model_evaluation(model, features, target, \n",
    "                     cv = cross_validation_setting):\n",
    "    scores = dict()\n",
    "    formatted_scores = dict()\n",
    "    formatted_scores['model'] = model\n",
    "    for scoring_name, scoring_function in SCORINGS.items():\n",
    "        scores[score_metric] = cross_validate(model, X, Y, \n",
    "                                              scoring = scoring_function,\n",
    "                                              cv = cross_validation_setting)\n",
    "        return scores[score_metric]\n",
    "#         formatted_scores[score_metric + \" score\"] = scores[score_metric].mean()\n",
    "#         formatted_scores[score_metric + \" std\"] = scores[score_metric].std()\n",
    "#     return formatted_scores\n",
    "\n",
    "def get_scores(Y_pred, Y_true):\n",
    "    f1 = f1_score(Y_true, Y_pred, average=None)\n",
    "    precision = precision_score(Y_true, Y_pred,\n",
    "                                average = None)\n",
    "    recall = recall_score(Y_true, Y_pred, \n",
    "                          average = None)\n",
    "    roc = roc_auc_score(Y_true, Y_pred, \n",
    "                        average = None)\n",
    "    return f1, precision, recall, roc\n",
    "\n",
    "def convert_df(X, Y):\n",
    "    return X.to_numpy(), Y.to_numpy()\n",
    "    \n",
    "def evaluate_model(model, X, Y, sk_fold):\n",
    "    X, Y = convert_df(X, Y)\n",
    "    f1_list, precision_list, recall_list, auc_list = [], [], [], []\n",
    "    \n",
    "    for train_index, test_index in sk_fold.split(X, Y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "    \n",
    "        f1, precision, recall, roc = get_scores(Y_pred, Y_test)\n",
    "        f1_list.append(f1)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        auc_list.append(roc)\n",
    "        \n",
    "    return format_return(f1_list, precision_list,\n",
    "                         recall_list, auc_list)\n",
    "\n",
    "COLUMNS = [\"F1 Average\", \"F1 Class 0\", \"F1 Class 1\",\n",
    "           \"Recall Average\", \"Recall Class 0\", \"Recall Class 1\",\n",
    "           \"AUC Average\", \"AUC Class 0\", \"AUC Class 1\",\n",
    "           \"Precision Average\", \"Precision Class 0\", \"Precision Class 1\"]\n",
    "\n",
    "def format_return(f1_list, precision_list,\n",
    "                  recall_list, auc_list):\n",
    "    dataframe = pd.DataFrame(columns = COLUMNS)\n",
    "    dataframe_line = []\n",
    "    aux = []\n",
    "    lists_of_score_list = []\n",
    "    lists_of_score_list.append(f1_list)\n",
    "    lists_of_score_list.append(precision_list)\n",
    "    lists_of_score_list.append(recall_list)\n",
    "    lists_of_score_list.append(auc_list)\n",
    "    for score_list in lists_of_score_list:\n",
    "        dataframe_line = dataframe.append(statistics.mean(flatten_list(score_list)))\n",
    "        dataframe_line = dataframe.append(statistics.mean([score[0] for score in score_list]))\n",
    "        dataframe_line = dataframe.append(statistics.mean([score[1] for score in score_list]))\n",
    "    dataframe.append(pd.DataFrame(dataframe_line, columns = COLUMNS), ignore_index = True)\n",
    "    return dataframe\n",
    "\n",
    "def flatten_list(lista):\n",
    "    return [value for sublist in lista for value in sublist]\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Config for every experiment\n",
    "\"\"\"\n",
    "RANDOM_STATE = 0\n",
    "VOTING_METHOD = 'soft'\n",
    "results = pd.DataFrame(columns = ['model', \"accuracy score\", \"accuracy std\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Getting the best weak learners (GridSearchCV section)\n",
    "\"\"\"\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-6cff55cf2e66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m                              refit = True)\n\u001b[0;32m     14\u001b[0m \u001b[0mselected_knn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_gridsearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselected_knn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcross_validation_setting\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;31m#results = results.append(model_evaluation(selected_knn, X , Y), ignore_index = True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-fa572bee637b>\u001b[0m in \u001b[0;36mevaluate_model\u001b[1;34m(model, X, Y, sk_fold)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     return format_return(f1_list, precision_list,\n\u001b[1;32m---> 80\u001b[1;33m                          recall_list, auc_list)\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m COLUMNS = [\"F1 Average\", \"F1 Class 0\", \"F1 Class 1\",\n",
      "\u001b[1;32m<ipython-input-49-fa572bee637b>\u001b[0m in \u001b[0;36mformat_return\u001b[1;34m(f1_list, precision_list, recall_list, auc_list)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[0mlists_of_score_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mscore_list\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlists_of_score_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mdataframe_line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflatten_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[0mdataframe_line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscore_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mdataframe_line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscore_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-fa572bee637b>\u001b[0m in \u001b[0;36mflatten_list\u001b[1;34m(lista)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mflatten_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlista\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlista\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "K Neighbors\n",
    "\"\"\"\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k_range = list(range(1,31))\n",
    "weight_options = [\"uniform\", \"distance\"]\n",
    "\n",
    "knn_grid = dict(n_neighbors = k_range, \n",
    "                weights = weight_options)\n",
    "knn = KNeighborsClassifier()\n",
    "knn_gridsearch = GridSearchCV(knn, param_grid = knn_grid,\n",
    "                             refit = True)\n",
    "selected_knn = knn_gridsearch.fit(X, Y).best_estimator_\n",
    "a,b,c = evaluate_model(selected_knn, X, Y, cross_validation_setting)\n",
    "#results = results.append(model_evaluation(selected_knn, X , Y), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flatten_list([[0,1], [2,3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg_grid={'C':[0.001,0.01,.09,1,5,10],\n",
    "              \"penalty\":[\"l1\",\"l2\"]} #l1 lasso l2 ridge\n",
    "lr = LogisticRegression(random_state=RANDOM_STATE)\n",
    "log_reg_gridsearch = GridSearchCV(lr, param_grid = log_reg_grid,\n",
    "                             refit = True)\n",
    "selected_log_reg = log_reg_gridsearch.fit(X,Y).best_estimator_\n",
    "evaluate_model(selected_log_reg, X.to_numpy(), Y.to_numpy())\n",
    "#results = results.append(model_evaluation(selected_log_reg, X, Y), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Support Vector Machines\n",
    "\"\"\"\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "            'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "            'kernel': ['rbf']} \n",
    "  \n",
    "svm_gridsearch = GridSearchCV(SVC(),\n",
    "                              param_grid = svm_grid,\n",
    "                              refit = True)\n",
    "\n",
    "selected_svm = svm_gridsearch.fit(X,Y).best_estimator_\n",
    "model_evaluation(selected_svm, X , Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "\n",
    "nb_params = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "nb_gridsearch = GridSearchCV(estimator=nb, \n",
    "                     param_grid = nb_params,\n",
    "                     refit = True)\n",
    "selected_nb = nb_gridsearch.fit(X,Y).best_estimator_\n",
    "model_evaluation(selected_nb, X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Boosting Algorithms\"\"\"\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "boosting_models = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost\n",
    "ab_param_grid = {\n",
    "    'n_estimators' : [100, 300, 500],\n",
    "    'learning_rate' : [1e-3, 1e-2, 1e-1, 1]\n",
    "}\n",
    "ab_model = AdaBoostClassifier(random_state = RANDOM_STATE)\n",
    "xgb_gridsearch = GridSearchCV(ab_model,\n",
    "                              param_grid = ab_param_grid,\n",
    "                              refit = True)\n",
    "\n",
    "selected_xgb = xgb_gridsearch.fit(X, Y).best_estimator_\n",
    "model_evaluation(selected_xgb, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "parameters = {\n",
    "            'max_depth': [3, 4, 5],\n",
    "            'learning_rate': [0.01, 0.1, 1],\n",
    "            'n_estimators': [200, 400],\n",
    "            'gamma': [0.01, 0.1, 0.2],\n",
    "            'min_child_weight': [0, 0.5, 1],\n",
    "            'max_delta_step': [0],\n",
    "            'subsample': [0.7, 1],\n",
    "            'colsample_bytree': [0.6, 1],\n",
    "            'reg_alpha': [0, 1e-2, 1],\n",
    "            'reg_lambda': [0, 1e-2, 1],\n",
    "            }\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(silent = True,\n",
    "                              random_state = RANDOM_STATE)\n",
    "\n",
    "xgb_gridsearch = GridSearchCV(xgb_model,\n",
    "                              parameters,\n",
    "                              refit = True)\n",
    "\n",
    "selected_xgb = xgb_gridsearch.fit(X, Y).best_estimator_\n",
    "model_evaluation(selected_xgb, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Bagging Algorithms\"\"\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bagging_models = dict()\n",
    "bagging_models['rf'] = RandomForestClassifier(random_state = RANDOM_STATE)\n",
    "bagging_models['et'] = ExtraTreesClassifier(random_state = RANDOM_STATE)\n",
    "bagging_models['bdt'] = BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                          random_state = RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#RandomForest\n",
    "rf_grid = {\n",
    "    'max_depth': [4, 5, 6],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [200, 400]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state = RANDOM_STATE)\n",
    "rf_gridsearch = GridSearchCV(rf, param_grid = rf_grid,\n",
    "                             refit = True)\n",
    "selected_rf = rf_gridsearch.fit(X, Y).best_estimator_\n",
    "model_evaluation(selected_rf, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra Trees\n",
    "\n",
    "et_grid = {\n",
    "    'max_depth': [4, 5, 6],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [200, 400],\n",
    "    'oob_score': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Stacking Ensemble\"\"\"\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "stacking_estimators = [\n",
    "    ('lr', selected_lr),\n",
    "    ('knn', selected_knn),\n",
    "    ('svm', selected_svm),\n",
    "    ('gnb', selected_nb),\n",
    "    ('dt', selected_dt)\n",
    "]\n",
    "\n",
    "final_estimator = selected_lr\n",
    "\n",
    "stacking_model = StackingClassifier(estimators = stacking_estimators,\n",
    "                                    final_estimator = final_estimator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Voting Ensemble\"\"\"\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_estimators = [\n",
    "    ('lr', LogisticRegression(random_state=RANDOM_STATE)),\n",
    "    ('knn', KNeighborsClassifier()),\n",
    "    ('svm', SVC(random_state=RANDOM_STATE)),\n",
    "    ('gnb', GaussianNB()),\n",
    "    ('dt', DecisionTreeClassifier(random_state=RANDOM_STATE))\n",
    "]\n",
    "\n",
    "voting_classifier = VotingClassifier(voting_estimators,\n",
    "                                     voting=VOTING_METHOD)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
