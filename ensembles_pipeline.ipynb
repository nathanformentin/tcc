{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from ipynb.fs.full.data_wrangling import * #Data preprocessing notebook\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "import statistics\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "SCORINGS = {\n",
    "    'f1': make_scorer(f1_score, average = None),\n",
    "    'precision': make_scorer(precision_score, average = None),\n",
    "    'recall': make_scorer(recall_score, average = None),\n",
    "    'roc_auc': make_scorer(roc_auc_score, average = None)\n",
    "}\n",
    "\n",
    "cv_splits = 10\n",
    "repetitions = 1\n",
    "RANDOM_STATE = 42\n",
    "cross_validation_setting = RepeatedStratifiedKFold(n_splits=cv_splits,\n",
    "                                                   n_repeats=repetitions,\n",
    "                                                   random_state= RANDOM_STATE)\n",
    "        \n",
    "def cross_validate(model, X_train, X_test, y_train, y_test, metric):\n",
    "    for index in range(len(X_train)):\n",
    "        model.fit(X_train, y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "def model_evaluation(model, features, target, \n",
    "                     cv = cross_validation_setting):\n",
    "    scores = dict()\n",
    "    formatted_scores = dict()\n",
    "    formatted_scores['model'] = model\n",
    "    for scoring_name, scoring_function in SCORINGS.items():\n",
    "        scores[score_metric] = cross_validate(model, X, Y, \n",
    "                                              scoring = scoring_function,\n",
    "                                              cv = cross_validation_setting)\n",
    "        return scores[score_metric]\n",
    "#         formatted_scores[score_metric + \" score\"] = scores[score_metric].mean()\n",
    "#         formatted_scores[score_metric + \" std\"] = scores[score_metric].std()\n",
    "#     return formatted_scores\n",
    "\n",
    "def get_scores(Y_pred, Y_true):\n",
    "    f1 = f1_score(Y_true, Y_pred, average=None)\n",
    "    precision = precision_score(Y_true, Y_pred,\n",
    "                                average = None)\n",
    "    recall = recall_score(Y_true, Y_pred, \n",
    "                          average = None)\n",
    "    roc = roc_auc_score(Y_true, Y_pred, \n",
    "                        average = None)\n",
    "    acc = accuracy_score(Y_true, Y_pred)\n",
    "    \n",
    "    return f1, precision, recall, roc, acc\n",
    "\n",
    "def convert_df(X, Y):\n",
    "    return X.to_numpy(), Y.to_numpy()\n",
    "\n",
    "def fault_cases(predictions, answers, indexes):\n",
    "    failed_cases = []\n",
    "    for i in range(len(predictions)):\n",
    "        if (predictions[i] != answers[i]):\n",
    "            failed_cases.append(indexes[i])\n",
    "    return failed_cases\n",
    "    \n",
    "def evaluate_model(model_name, model, X, Y, sk_fold):\n",
    "    X, Y = convert_df(X, Y)\n",
    "    f1_list, precision_list, recall_list, auc_list, acc_list = [], [], [], [], []\n",
    "    \n",
    "    for train_index, test_index in sk_fold.split(X, Y):\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        model.fit(X_train, Y_train)\n",
    "        \n",
    "        failed_cases_index = []\n",
    "        Y_pred = model.predict(X_test)\n",
    "        failed_cases_index.append(fault_cases(Y_pred, Y_test, test_index))\n",
    "    \n",
    "        f1, precision, recall, roc, acc = get_scores(Y_pred, Y_test)\n",
    "        f1_list.append(f1)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        auc_list.append(roc)\n",
    "        acc_list.append(acc)\n",
    "        \n",
    "    return format_return(model_name, f1_list, precision_list,\n",
    "                         recall_list, auc_list, acc_list), failed_cases_index[0]\n",
    "\n",
    "COLUMNS = [\"Model Name\", \"F1 Average\", \"F1 Class 0\", \"F1 Class 1\",\n",
    "           \"Recall Average\", \"Recall Class 0\", \"Recall Class 1\",\n",
    "           \"Precision Average\", \"Precision Class 0\", \"Precision Class 1\",\n",
    "           \"AUC\", \"Accuracy\"]\n",
    "\n",
    "def format_return(model_name, f1_list, precision_list,\n",
    "                  recall_list, auc_list, acc_list):\n",
    "    dataframe = pd.DataFrame(columns = COLUMNS)\n",
    "    dataframe_line = []\n",
    "    dataframe_line.append(model_name)\n",
    "    aux = []\n",
    "    lists_of_score_list = []\n",
    "    lists_of_score_list.append(f1_list)\n",
    "    lists_of_score_list.append(precision_list)\n",
    "    lists_of_score_list.append(recall_list)\n",
    "    # auc_list\n",
    "    for score_list in lists_of_score_list:\n",
    "        dataframe_line.extend((statistics.mean(flatten_list(score_list)),\n",
    "                               statistics.mean([score[0] for score in score_list]),\n",
    "                               statistics.mean([score[1] for score in score_list])))\n",
    "    dataframe_line.append(statistics.mean(auc_list))\n",
    "    dataframe_line.append(statistics.mean(acc_list))\n",
    "    return dataframe.append(pd.Series(dataframe_line, index = COLUMNS),\n",
    "                            ignore_index = True)\n",
    "\n",
    "def flatten_list(lista):\n",
    "    return [value for sublist in lista for value in sublist]\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Config for every experiment\n",
    "\"\"\"\n",
    "RANDOM_STATE = 0\n",
    "VOTING_METHOD = 'hard'\n",
    "results = pd.DataFrame(columns = COLUMNS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Getting the best weak learners (GridSearchCV section)\n",
    "\"\"\"\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "K Neighbors\n",
    "\"\"\"\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k_range = list(range(1,31))\n",
    "weight_options = [\"uniform\", \"distance\"]\n",
    "\n",
    "knn_grid = dict(n_neighbors = k_range, \n",
    "                weights = weight_options)\n",
    "knn = KNeighborsClassifier()\n",
    "knn_gridsearch = GridSearchCV(knn, param_grid = knn_grid,\n",
    "                             refit = True)\n",
    "selected_knn = knn_gridsearch.fit(X, Y).best_estimator_\n",
    "failed_cases = []\n",
    "scores, failed = evaluate_model(\"KNN\", selected_knn, X, Y, cross_validation_setting)\n",
    "results = results.append(scores)\n",
    "failed_cases.append(failed)\n",
    "#results = results.append(model_evaluation(selected_knn, X , Y), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg_grid={'C':[0.001,0.01,.09,1,5,10],\n",
    "              \"penalty\":[\"l1\",\"l2\"]} #l1 lasso l2 ridge\n",
    "lr = LogisticRegression(random_state=RANDOM_STATE)\n",
    "log_reg_gridsearch = GridSearchCV(lr, param_grid = log_reg_grid,\n",
    "                             refit = True)\n",
    "selected_log_reg = log_reg_gridsearch.fit(X,Y).best_estimator_\n",
    "scores, failed = evaluate_model(\"Logistic Regression\",selected_log_reg, X, Y, cross_validation_setting)\n",
    "results = results.append(scores)\n",
    "failed_cases.append(failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Support Vector Machines\n",
    "\"\"\"\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "            'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "            'kernel': ['rbf']} \n",
    "  \n",
    "svm_gridsearch = GridSearchCV(SVC(),\n",
    "                              param_grid = svm_grid,\n",
    "                              refit = True)\n",
    "\n",
    "selected_svm = svm_gridsearch.fit(X,Y).best_estimator_\n",
    "scores, failed = evaluate_model(\"SVM\",selected_svm, X, Y, cross_validation_setting)\n",
    "results = results.append(scores)\n",
    "failed_cases.append(failed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "\n",
    "nb_params = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "nb_gridsearch = GridSearchCV(estimator=nb, \n",
    "                     param_grid = nb_params,\n",
    "                     refit = True)\n",
    "selected_nb = nb_gridsearch.fit(X,Y).best_estimator_\n",
    "scores, failed = evaluate_model(\"Naive Bayes\",selected_nb, X, Y, cross_validation_setting)\n",
    "results = results.append(scores)\n",
    "failed_cases.append(failed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_para = {'criterion':['gini','entropy'],\n",
    "             'max_depth':[4,5,10]}\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "tree_gridsearch = GridSearchCV(dt, param_grid = tree_para, cv=5)\n",
    "selected_dt = tree_gridsearch.fit(X, Y).best_estimator_\n",
    "scores, failed = evaluate_model(\"Decision Trees\",selected_dt, X, Y, cross_validation_setting)\n",
    "results = results.append(scores)\n",
    "failed_cases.append(failed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Boosting Algorithms\"\"\"\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "boosting_models = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost\n",
    "ab_param_grid = {\n",
    "    'n_estimators' : [100, 300, 500],\n",
    "    'learning_rate' : [1e-3, 1e-2, 1e-1, 1]\n",
    "}\n",
    "ab_model = AdaBoostClassifier(random_state = RANDOM_STATE)\n",
    "ab_gridsearchcv = GridSearchCV(ab_model,\n",
    "                              param_grid = ab_param_grid,\n",
    "                              refit = True)\n",
    "\n",
    "selected_ab = ab_gridsearchcv.fit(X, Y).best_estimator_\n",
    "scores, failed = evaluate_model(\"AdaBoost\",selected_ab, X, Y, cross_validation_setting)\n",
    "results = results.append(scores)\n",
    "failed_cases.append(failed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "parameters = {\n",
    "            'max_depth': [3, 4, 5],\n",
    "            'learning_rate': [0.01, 0.1, 1],\n",
    "            'n_estimators': [200, 400],\n",
    "            'gamma': [0.01, 0.1, 0.2],\n",
    "            'min_child_weight': [0, 0.5, 1],\n",
    "            'max_delta_step': [0],\n",
    "            'subsample': [0.7, 1],\n",
    "            'colsample_bytree': [0.6, 1],\n",
    "            'reg_alpha': [0, 1e-2, 1],\n",
    "            'reg_lambda': [0, 1e-2, 1],\n",
    "            }\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(silent = True,\n",
    "                              random_state = RANDOM_STATE)\n",
    "\n",
    "xgb_gridsearch = GridSearchCV(xgb_model,\n",
    "                              parameters,\n",
    "                              refit = True)\n",
    "\n",
    "selected_xgb = xgb_gridsearch.fit(X, Y).best_estimator_\n",
    "scores, failed = evaluate_model(\"XGB\", selected_xgb, X, Y, cross_validation_setting)\n",
    "results = results.append(scores)\n",
    "failed_cases.append(failed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#RandomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_grid = {\n",
    "    'max_depth': [4, 5, 6],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [200, 400]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state = RANDOM_STATE)\n",
    "rf_gridsearch = GridSearchCV(rf, param_grid = rf_grid,\n",
    "                             refit = True)\n",
    "selected_rf = rf_gridsearch.fit(X, Y).best_estimator_\n",
    "scores, failed = evaluate_model(\"RandomForest\",selected_rf, X, Y, cross_validation_setting)\n",
    "results = results.append(scores)\n",
    "failed_cases.append(failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "et_grid = {\n",
    "    'max_depth': [4, 5, 6],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [200, 400],\n",
    "    'oob_score': [True, False]\n",
    "}\n",
    "\n",
    "et_clf = ExtraTreesClassifier(random_state = RANDOM_STATE)\n",
    "et_gridsearch = GridSearchCV(et_clf, param_grid = et_grid,\n",
    "                             refit = True)\n",
    "selected_et = et_gridsearch.fit(X, Y).best_estimator_\n",
    "scores, failed = evaluate_model(\"ExtraTrees\",selected_et, X, Y, cross_validation_setting)\n",
    "results = results.append(scores)\n",
    "failed_cases.append(failed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BaggingClassifier(DecisionTree) \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagging_param_grid = {\n",
    "    'base_estimator__max_depth' : [1, 2, 3, 4, 5],\n",
    "    'max_samples' : [0.05, 0.1, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "bg_clf = BaggingClassifier(base_estimator=selected_dt,\n",
    "                           random_state = RANDOM_STATE)\n",
    "bg_gridsearch = GridSearchCV(bg_clf, param_grid = bagging_param_grid,\n",
    "                             refit = True)\n",
    "selected_bg = bg_gridsearch.fit(X, Y).best_estimator_\n",
    "scores, failed = evaluate_model(\"Bagging (Decision Trees)\",selected_bg, X, Y, cross_validation_setting)\n",
    "results = results.append(scores)\n",
    "failed_cases.append(failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Nathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Stacking Ensemble\"\"\"\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "stacking_estimators = [\n",
    "    ('lr', selected_log_reg),\n",
    "    ('knn', selected_knn),\n",
    "    ('svm', selected_svm),\n",
    "    ('gnb', selected_nb),\n",
    "    ('dt', selected_dt)\n",
    "]\n",
    "\n",
    "final_estimator = selected_svm\n",
    "\n",
    "stacking_model = StackingClassifier(estimators = stacking_estimators,\n",
    "                                    final_estimator = final_estimator)\n",
    "\n",
    "scores, failed = evaluate_model(\"Stacking (LR, KNN, SVM, NB, DT)\",stacking_model, X, Y, cross_validation_setting)\n",
    "# results = results.append(scores)\n",
    "# failed_cases.append(failed)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>F1 Average</th>\n",
       "      <th>F1 Class 0</th>\n",
       "      <th>F1 Class 1</th>\n",
       "      <th>Recall Average</th>\n",
       "      <th>Recall Class 0</th>\n",
       "      <th>Recall Class 1</th>\n",
       "      <th>Precision Average</th>\n",
       "      <th>Precision Class 0</th>\n",
       "      <th>Precision Class 1</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stacking (LR, KNN, SVM, NB, DT)</td>\n",
       "      <td>0.772531</td>\n",
       "      <td>0.770303</td>\n",
       "      <td>0.774759</td>\n",
       "      <td>0.774158</td>\n",
       "      <td>0.756386</td>\n",
       "      <td>0.791929</td>\n",
       "      <td>0.773265</td>\n",
       "      <td>0.78653</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.773265</td>\n",
       "      <td>0.7728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model Name  F1 Average  F1 Class 0  F1 Class 1  \\\n",
       "0  Stacking (LR, KNN, SVM, NB, DT)    0.772531    0.770303    0.774759   \n",
       "\n",
       "   Recall Average  Recall Class 0  Recall Class 1  Precision Average  \\\n",
       "0        0.774158        0.756386        0.791929           0.773265   \n",
       "\n",
       "   Precision Class 0  Precision Class 1       AUC  Accuracy  \n",
       "0            0.78653               0.76  0.773265    0.7728  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Voting Ensemble\"\"\"\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_estimators = [\n",
    "    ('lr', selected_log_reg),\n",
    "    ('knn', selected_knn),\n",
    "    ('svm', selected_svm),\n",
    "    ('gnb', selected_nb),\n",
    "    ('dt', selected_dt)\n",
    "]\n",
    "\n",
    "voting_classifier = VotingClassifier(voting_estimators,\n",
    "                                     voting=VOTING_METHOD)\n",
    "scores, failed = evaluate_model(\"Voting (LR, KNN, SVM, NB, DT)\",voting_classifier, X, Y, cross_validation_setting)\n",
    "results = results.append(scores)\n",
    "failed_cases.append(failed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>F1 Average</th>\n",
       "      <th>F1 Class 0</th>\n",
       "      <th>F1 Class 1</th>\n",
       "      <th>Recall Average</th>\n",
       "      <th>Recall Class 0</th>\n",
       "      <th>Recall Class 1</th>\n",
       "      <th>Precision Average</th>\n",
       "      <th>Precision Class 0</th>\n",
       "      <th>Precision Class 1</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.611198</td>\n",
       "      <td>0.578264</td>\n",
       "      <td>0.644132</td>\n",
       "      <td>0.615988</td>\n",
       "      <td>0.617013</td>\n",
       "      <td>0.614964</td>\n",
       "      <td>0.612646</td>\n",
       "      <td>0.546831</td>\n",
       "      <td>0.678462</td>\n",
       "      <td>0.612646</td>\n",
       "      <td>0.614787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.374852</td>\n",
       "      <td>0.665757</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.347790</td>\n",
       "      <td>0.515276</td>\n",
       "      <td>0.180303</td>\n",
       "      <td>0.530063</td>\n",
       "      <td>0.977049</td>\n",
       "      <td>0.083077</td>\n",
       "      <td>0.530063</td>\n",
       "      <td>0.515467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.772531</td>\n",
       "      <td>0.770303</td>\n",
       "      <td>0.774759</td>\n",
       "      <td>0.774158</td>\n",
       "      <td>0.756386</td>\n",
       "      <td>0.791929</td>\n",
       "      <td>0.773265</td>\n",
       "      <td>0.786530</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.773265</td>\n",
       "      <td>0.772800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.372808</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.687283</td>\n",
       "      <td>0.304217</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.528435</td>\n",
       "      <td>0.517566</td>\n",
       "      <td>0.045902</td>\n",
       "      <td>0.989231</td>\n",
       "      <td>0.517566</td>\n",
       "      <td>0.532952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Trees</td>\n",
       "      <td>0.743622</td>\n",
       "      <td>0.731886</td>\n",
       "      <td>0.755359</td>\n",
       "      <td>0.751644</td>\n",
       "      <td>0.749868</td>\n",
       "      <td>0.753420</td>\n",
       "      <td>0.745167</td>\n",
       "      <td>0.724180</td>\n",
       "      <td>0.766154</td>\n",
       "      <td>0.745167</td>\n",
       "      <td>0.745822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.774186</td>\n",
       "      <td>0.772098</td>\n",
       "      <td>0.776274</td>\n",
       "      <td>0.775681</td>\n",
       "      <td>0.756535</td>\n",
       "      <td>0.794828</td>\n",
       "      <td>0.774918</td>\n",
       "      <td>0.789836</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.774918</td>\n",
       "      <td>0.774400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.770169</td>\n",
       "      <td>0.768350</td>\n",
       "      <td>0.771987</td>\n",
       "      <td>0.771977</td>\n",
       "      <td>0.752681</td>\n",
       "      <td>0.791272</td>\n",
       "      <td>0.770971</td>\n",
       "      <td>0.786557</td>\n",
       "      <td>0.755385</td>\n",
       "      <td>0.770971</td>\n",
       "      <td>0.770432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.774923</td>\n",
       "      <td>0.773684</td>\n",
       "      <td>0.776162</td>\n",
       "      <td>0.776725</td>\n",
       "      <td>0.756837</td>\n",
       "      <td>0.796613</td>\n",
       "      <td>0.775788</td>\n",
       "      <td>0.793115</td>\n",
       "      <td>0.758462</td>\n",
       "      <td>0.775788</td>\n",
       "      <td>0.775187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>0.773398</td>\n",
       "      <td>0.772729</td>\n",
       "      <td>0.774066</td>\n",
       "      <td>0.775173</td>\n",
       "      <td>0.753300</td>\n",
       "      <td>0.797046</td>\n",
       "      <td>0.774300</td>\n",
       "      <td>0.794754</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.774300</td>\n",
       "      <td>0.773606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging (Decision Trees)</td>\n",
       "      <td>0.774186</td>\n",
       "      <td>0.772098</td>\n",
       "      <td>0.776274</td>\n",
       "      <td>0.775681</td>\n",
       "      <td>0.756535</td>\n",
       "      <td>0.794828</td>\n",
       "      <td>0.774918</td>\n",
       "      <td>0.789836</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.774918</td>\n",
       "      <td>0.774400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stacking (LR, KNN, SVM, NB, DT)</td>\n",
       "      <td>0.770924</td>\n",
       "      <td>0.767283</td>\n",
       "      <td>0.774566</td>\n",
       "      <td>0.772350</td>\n",
       "      <td>0.758186</td>\n",
       "      <td>0.786513</td>\n",
       "      <td>0.771488</td>\n",
       "      <td>0.778361</td>\n",
       "      <td>0.764615</td>\n",
       "      <td>0.771488</td>\n",
       "      <td>0.771232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Voting (LR, KNN, SVM, NB, DT)</td>\n",
       "      <td>0.764727</td>\n",
       "      <td>0.755302</td>\n",
       "      <td>0.774152</td>\n",
       "      <td>0.767795</td>\n",
       "      <td>0.765487</td>\n",
       "      <td>0.770102</td>\n",
       "      <td>0.765168</td>\n",
       "      <td>0.748798</td>\n",
       "      <td>0.781538</td>\n",
       "      <td>0.765168</td>\n",
       "      <td>0.765683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model Name  F1 Average  F1 Class 0  F1 Class 1  \\\n",
       "0                              KNN    0.611198    0.578264    0.644132   \n",
       "0              Logistic Regression    0.374852    0.665757    0.083946   \n",
       "0                              SVM    0.772531    0.770303    0.774759   \n",
       "0                      Naive Bayes    0.372808    0.058333    0.687283   \n",
       "0                   Decision Trees    0.743622    0.731886    0.755359   \n",
       "0                         AdaBoost    0.774186    0.772098    0.776274   \n",
       "0                              XGB    0.770169    0.768350    0.771987   \n",
       "0                     RandomForest    0.774923    0.773684    0.776162   \n",
       "0                       ExtraTrees    0.773398    0.772729    0.774066   \n",
       "0         Bagging (Decision Trees)    0.774186    0.772098    0.776274   \n",
       "0  Stacking (LR, KNN, SVM, NB, DT)    0.770924    0.767283    0.774566   \n",
       "0    Voting (LR, KNN, SVM, NB, DT)    0.764727    0.755302    0.774152   \n",
       "\n",
       "   Recall Average  Recall Class 0  Recall Class 1  Precision Average  \\\n",
       "0        0.615988        0.617013        0.614964           0.612646   \n",
       "0        0.347790        0.515276        0.180303           0.530063   \n",
       "0        0.774158        0.756386        0.791929           0.773265   \n",
       "0        0.304217        0.080000        0.528435           0.517566   \n",
       "0        0.751644        0.749868        0.753420           0.745167   \n",
       "0        0.775681        0.756535        0.794828           0.774918   \n",
       "0        0.771977        0.752681        0.791272           0.770971   \n",
       "0        0.776725        0.756837        0.796613           0.775788   \n",
       "0        0.775173        0.753300        0.797046           0.774300   \n",
       "0        0.775681        0.756535        0.794828           0.774918   \n",
       "0        0.772350        0.758186        0.786513           0.771488   \n",
       "0        0.767795        0.765487        0.770102           0.765168   \n",
       "\n",
       "   Precision Class 0  Precision Class 1       AUC  Accuracy  \n",
       "0           0.546831           0.678462  0.612646  0.614787  \n",
       "0           0.977049           0.083077  0.530063  0.515467  \n",
       "0           0.786530           0.760000  0.773265  0.772800  \n",
       "0           0.045902           0.989231  0.517566  0.532952  \n",
       "0           0.724180           0.766154  0.745167  0.745822  \n",
       "0           0.789836           0.760000  0.774918  0.774400  \n",
       "0           0.786557           0.755385  0.770971  0.770432  \n",
       "0           0.793115           0.758462  0.775788  0.775187  \n",
       "0           0.794754           0.753846  0.774300  0.773606  \n",
       "0           0.789836           0.760000  0.774918  0.774400  \n",
       "0           0.778361           0.764615  0.771488  0.771232  \n",
       "0           0.748798           0.781538  0.765168  0.765683  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"resultados1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6,\n",
       " 28,\n",
       " 44,\n",
       " 145,\n",
       " 178,\n",
       " 190,\n",
       " 198,\n",
       " 218,\n",
       " 230,\n",
       " 254,\n",
       " 260,\n",
       " 263,\n",
       " 283,\n",
       " 295,\n",
       " 321,\n",
       " 350,\n",
       " 354,\n",
       " 393,\n",
       " 411,\n",
       " 431,\n",
       " 481,\n",
       " 482,\n",
       " 500,\n",
       " 516,\n",
       " 521,\n",
       " 534,\n",
       " 541,\n",
       " 546,\n",
       " 556,\n",
       " 585,\n",
       " 631,\n",
       " 634,\n",
       " 637,\n",
       " 652,\n",
       " 707,\n",
       " 913,\n",
       " 923,\n",
       " 948,\n",
       " 955,\n",
       " 1008,\n",
       " 1011,\n",
       " 1060,\n",
       " 1087,\n",
       " 1118,\n",
       " 1190,\n",
       " 1200,\n",
       " 1,\n",
       " 13,\n",
       " 37,\n",
       " 79,\n",
       " 104,\n",
       " 117,\n",
       " 145,\n",
       " 179,\n",
       " 197,\n",
       " 198,\n",
       " 204,\n",
       " 208,\n",
       " 218,\n",
       " 260,\n",
       " 263,\n",
       " 276,\n",
       " 295,\n",
       " 299,\n",
       " 307,\n",
       " 314,\n",
       " 372,\n",
       " 374,\n",
       " 386,\n",
       " 411,\n",
       " 418,\n",
       " 430,\n",
       " 431,\n",
       " 469,\n",
       " 490,\n",
       " 500,\n",
       " 516,\n",
       " 521,\n",
       " 534,\n",
       " 538,\n",
       " 541,\n",
       " 546,\n",
       " 554,\n",
       " 585,\n",
       " 616,\n",
       " 631,\n",
       " 634,\n",
       " 662,\n",
       " 670,\n",
       " 692,\n",
       " 693,\n",
       " 705,\n",
       " 734,\n",
       " 741,\n",
       " 754,\n",
       " 761,\n",
       " 772,\n",
       " 838,\n",
       " 893,\n",
       " 896,\n",
       " 908,\n",
       " 975,\n",
       " 993,\n",
       " 999,\n",
       " 1011,\n",
       " 1087,\n",
       " 1118,\n",
       " 1149,\n",
       " 1152,\n",
       " 1244,\n",
       " 80,\n",
       " 143,\n",
       " 145,\n",
       " 192,\n",
       " 218,\n",
       " 254,\n",
       " 260,\n",
       " 263,\n",
       " 350,\n",
       " 354,\n",
       " 372,\n",
       " 374,\n",
       " 397,\n",
       " 411,\n",
       " 431,\n",
       " 469,\n",
       " 500,\n",
       " 511,\n",
       " 516,\n",
       " 541,\n",
       " 554,\n",
       " 556,\n",
       " 577,\n",
       " 612,\n",
       " 631,\n",
       " 634,\n",
       " 705,\n",
       " 761,\n",
       " 890,\n",
       " 908,\n",
       " 1058,\n",
       " 1118,\n",
       " 1152,\n",
       " 1213,\n",
       " 6,\n",
       " 28,\n",
       " 44,\n",
       " 80,\n",
       " 155,\n",
       " 164,\n",
       " 171,\n",
       " 178,\n",
       " 190,\n",
       " 192,\n",
       " 230,\n",
       " 254,\n",
       " 283,\n",
       " 303,\n",
       " 321,\n",
       " 349,\n",
       " 350,\n",
       " 354,\n",
       " 393,\n",
       " 397,\n",
       " 423,\n",
       " 473,\n",
       " 481,\n",
       " 482,\n",
       " 486,\n",
       " 511,\n",
       " 517,\n",
       " 556,\n",
       " 577,\n",
       " 579,\n",
       " 612,\n",
       " 637,\n",
       " 642,\n",
       " 652,\n",
       " 707,\n",
       " 729,\n",
       " 863,\n",
       " 871,\n",
       " 890,\n",
       " 897,\n",
       " 913,\n",
       " 923,\n",
       " 933,\n",
       " 948,\n",
       " 955,\n",
       " 962,\n",
       " 971,\n",
       " 1008,\n",
       " 1033,\n",
       " 1048,\n",
       " 1058,\n",
       " 1060,\n",
       " 1108,\n",
       " 1139,\n",
       " 1160,\n",
       " 1190,\n",
       " 1195,\n",
       " 1200,\n",
       " 1205,\n",
       " 1213,\n",
       " 80,\n",
       " 145,\n",
       " 192,\n",
       " 204,\n",
       " 218,\n",
       " 254,\n",
       " 260,\n",
       " 263,\n",
       " 350,\n",
       " 354,\n",
       " 374,\n",
       " 393,\n",
       " 397,\n",
       " 411,\n",
       " 431,\n",
       " 469,\n",
       " 500,\n",
       " 511,\n",
       " 516,\n",
       " 517,\n",
       " 541,\n",
       " 554,\n",
       " 556,\n",
       " 612,\n",
       " 631,\n",
       " 634,\n",
       " 705,\n",
       " 707,\n",
       " 890,\n",
       " 893,\n",
       " 913,\n",
       " 1118,\n",
       " 1213,\n",
       " 80,\n",
       " 145,\n",
       " 192,\n",
       " 218,\n",
       " 254,\n",
       " 260,\n",
       " 263,\n",
       " 350,\n",
       " 354,\n",
       " 372,\n",
       " 374,\n",
       " 397,\n",
       " 411,\n",
       " 431,\n",
       " 469,\n",
       " 500,\n",
       " 511,\n",
       " 516,\n",
       " 541,\n",
       " 554,\n",
       " 556,\n",
       " 577,\n",
       " 612,\n",
       " 631,\n",
       " 634,\n",
       " 705,\n",
       " 761,\n",
       " 890,\n",
       " 908,\n",
       " 1118,\n",
       " 1152,\n",
       " 1213,\n",
       " [80,\n",
       "  145,\n",
       "  192,\n",
       "  218,\n",
       "  254,\n",
       "  260,\n",
       "  263,\n",
       "  350,\n",
       "  354,\n",
       "  372,\n",
       "  374,\n",
       "  397,\n",
       "  411,\n",
       "  431,\n",
       "  469,\n",
       "  500,\n",
       "  511,\n",
       "  516,\n",
       "  541,\n",
       "  554,\n",
       "  556,\n",
       "  577,\n",
       "  612,\n",
       "  631,\n",
       "  634,\n",
       "  705,\n",
       "  761,\n",
       "  890,\n",
       "  908,\n",
       "  1118,\n",
       "  1152,\n",
       "  1213],\n",
       " [80,\n",
       "  145,\n",
       "  192,\n",
       "  218,\n",
       "  254,\n",
       "  260,\n",
       "  263,\n",
       "  350,\n",
       "  354,\n",
       "  372,\n",
       "  374,\n",
       "  397,\n",
       "  411,\n",
       "  431,\n",
       "  469,\n",
       "  500,\n",
       "  511,\n",
       "  516,\n",
       "  541,\n",
       "  554,\n",
       "  556,\n",
       "  577,\n",
       "  612,\n",
       "  631,\n",
       "  634,\n",
       "  705,\n",
       "  761,\n",
       "  890,\n",
       "  908,\n",
       "  1087,\n",
       "  1118,\n",
       "  1152,\n",
       "  1213],\n",
       " [80,\n",
       "  145,\n",
       "  192,\n",
       "  218,\n",
       "  254,\n",
       "  260,\n",
       "  263,\n",
       "  350,\n",
       "  354,\n",
       "  372,\n",
       "  374,\n",
       "  397,\n",
       "  411,\n",
       "  431,\n",
       "  469,\n",
       "  500,\n",
       "  511,\n",
       "  516,\n",
       "  541,\n",
       "  554,\n",
       "  556,\n",
       "  577,\n",
       "  612,\n",
       "  631,\n",
       "  634,\n",
       "  705,\n",
       "  761,\n",
       "  890,\n",
       "  908,\n",
       "  1118,\n",
       "  1152,\n",
       "  1213],\n",
       " [80,\n",
       "  145,\n",
       "  192,\n",
       "  218,\n",
       "  254,\n",
       "  260,\n",
       "  263,\n",
       "  350,\n",
       "  354,\n",
       "  372,\n",
       "  374,\n",
       "  397,\n",
       "  411,\n",
       "  431,\n",
       "  469,\n",
       "  500,\n",
       "  511,\n",
       "  516,\n",
       "  541,\n",
       "  554,\n",
       "  556,\n",
       "  577,\n",
       "  612,\n",
       "  631,\n",
       "  634,\n",
       "  705,\n",
       "  761,\n",
       "  890,\n",
       "  908,\n",
       "  1118,\n",
       "  1152,\n",
       "  1213],\n",
       " [80,\n",
       "  145,\n",
       "  192,\n",
       "  218,\n",
       "  254,\n",
       "  260,\n",
       "  263,\n",
       "  350,\n",
       "  354,\n",
       "  374,\n",
       "  397,\n",
       "  411,\n",
       "  431,\n",
       "  469,\n",
       "  500,\n",
       "  511,\n",
       "  516,\n",
       "  541,\n",
       "  554,\n",
       "  556,\n",
       "  577,\n",
       "  612,\n",
       "  631,\n",
       "  634,\n",
       "  705,\n",
       "  761,\n",
       "  890,\n",
       "  908,\n",
       "  1118,\n",
       "  1152,\n",
       "  1213],\n",
       " [80,\n",
       "  145,\n",
       "  192,\n",
       "  218,\n",
       "  254,\n",
       "  260,\n",
       "  263,\n",
       "  350,\n",
       "  354,\n",
       "  374,\n",
       "  393,\n",
       "  397,\n",
       "  411,\n",
       "  431,\n",
       "  469,\n",
       "  500,\n",
       "  511,\n",
       "  516,\n",
       "  541,\n",
       "  554,\n",
       "  556,\n",
       "  612,\n",
       "  631,\n",
       "  634,\n",
       "  705,\n",
       "  707,\n",
       "  890,\n",
       "  913,\n",
       "  1118,\n",
       "  1213]]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.int32' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-259-1dfaf9a7d7a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfailed_cases\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflatten_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfailed_cases\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcounter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfailed_cases\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcounter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-235-f911d0ceab25>\u001b[0m in \u001b[0;36mflatten_list\u001b[1;34m(lista)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mflatten_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlista\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlista\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-235-f911d0ceab25>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mflatten_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlista\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlista\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.int32' object is not iterable"
     ]
    }
   ],
   "source": [
    "failed_cases = flatten_list(failed_cases)\n",
    "counter = Counter(chain(failed_cases))\n",
    "counter = sorted(counter.items(), key=lambda x: x[1], reverse = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
